{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fd7293-5f2c-4d35-84d3-a4feb87c4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading secret ADLS_adlsthuehomelakehousedev_access_key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/bitnami/python/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hudi#hudi-spark3.3-bundle_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9305cf4b-180a-4df4-9bc6-a48718da6f96;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hudi#hudi-spark3.3-bundle_2.12;0.13.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.3 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.13.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.2.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.43.v20210629 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 1961ms :: artifacts dl 104ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.13.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.2.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.3 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.hudi#hudi-spark3.3-bundle_2.12;0.13.1 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.43.v20210629 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9305cf4b-180a-4df4-9bc6-a48718da6f96\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/15ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 20:26:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, col\n",
    "import json\n",
    "from cdk.services.api.energi_data_service import EnergiDataService\n",
    "from cdk.common_modules.access.secrets import Secrets\n",
    "from cdk.common_modules.utility.spark_config import SparkConfig\n",
    "from cdk.common_modules.utility.spark_session_builder import SparkSessionBuilder\n",
    "\n",
    "storage_account_name = \"adlsthuehomelakehousedev\"\n",
    "\n",
    "# Set Spark configurations\n",
    "spark_config = SparkConfig(Secrets())\n",
    "\n",
    "# Add jars to install\n",
    "spark_config.add_jars_to_install(['hudi', 'azure_storage'])\n",
    "\n",
    "# Add storage account access\n",
    "spark_config.add_storage_account_access(storage_account_name, method='access_key')\n",
    "\n",
    "# Build SparkSession\n",
    "spark = SparkSessionBuilder(\"ViewAzureData\", \"spark://spark-master:7077\", spark_config).build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781facba-5fc0-4c8d-83fc-806e303c7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ConsumptionDK3619codehour\"\n",
    "dataset_path = \"energi_data_service\"\n",
    "container_name = \"landing\"\n",
    "\n",
    "# landing_path = f\"hdfs://namenode:9000/data/landing/energi_data_service/{dataset_name}\"\n",
    "landing_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{dataset_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6a6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 20:27:28 WARN DFSPropertiesConfiguration: Cannot find HUDI_CONF_DIR, please set it as the dir of hudi-defaults.conf\n",
      "23/09/24 20:27:28 WARN DFSPropertiesConfiguration: Properties file file:/etc/hudi/conf/hudi-defaults.conf not found. Ignoring to load props file\n"
     ]
    }
   ],
   "source": [
    "# pyspark\n",
    "df = spark. \\\n",
    "  read. \\\n",
    "  format(\"hudi\"). \\\n",
    "  load(landing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809e45c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+--------+--------------------+--------+--------------------+-------------------+-------------------+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|Consumption_MWh|DK19Code|           DK19Title|DK36Code|           DK36Title|             HourDK|            HourUTC|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+--------+--------------------+--------+--------------------+-------------------+-------------------+\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|      204.35082|       A|Landbrug, skovbru...|       A|Landbrug, skovbru...|2023-09-02T20:00:00|2023-09-02T18:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|      26.371918|       C|            Industri|      CK|      Maskinindustri|2023-09-02T15:00:00|2023-09-02T13:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|      177.94455|       D|     Energiforsyning|       D|     Energiforsyning|2023-09-02T12:00:00|2023-09-02T10:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|       4.820768|       C|            Industri|      CI|  Elektronikindustri|2023-09-02T22:00:00|2023-09-02T20:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|      72.968625|       E|Vandforsyning og ...|       E|Vandforsyning og ...|2023-09-02T11:00:00|2023-09-02T09:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|      97.351255|       C|            Industri|      CG|Plast-, glas- og ...|2023-09-02T14:00:00|2023-09-02T12:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|     148.711108|       J|Information og ko...|   JB_JC|Telekommunikation...|2023-09-02T05:00:00|2023-09-02T03:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|     175.628002|       C|            Industri|      CA|FÃ¸de-, drikke- og...|2023-09-02T12:00:00|2023-09-02T10:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|       5.665797|       C|            Industri|      CJ|Fremst. af elektr...|2023-09-02T16:00:00|2023-09-02T14:00:00|\n",
      "|  20230924073511918|20230924073511918...|HourUTC:2023-09-0...|                      |d06cf81e-b1df-44d...|       9.609746|       J|Information og ko...|      JA| Forlag, tv og radio|2023-09-02T15:00:00|2023-09-02T13:00:00|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+--------+--------------------+--------+--------------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db59e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------------------+\n",
      "|DK19Code|DK36Code|             HourDK|\n",
      "+--------+--------+-------------------+\n",
      "|       C|      CI|2023-09-02T00:00:00|\n",
      "|       C|      CI|2023-09-02T01:00:00|\n",
      "|       C|      CI|2023-09-02T02:00:00|\n",
      "|       C|      CI|2023-09-02T03:00:00|\n",
      "|       C|      CI|2023-09-02T04:00:00|\n",
      "|       C|      CI|2023-09-02T05:00:00|\n",
      "|       C|      CI|2023-09-02T06:00:00|\n",
      "|       C|      CI|2023-09-02T07:00:00|\n",
      "|       C|      CI|2023-09-02T08:00:00|\n",
      "|       C|      CI|2023-09-02T09:00:00|\n",
      "|       C|      CI|2023-09-02T10:00:00|\n",
      "|       C|      CI|2023-09-02T11:00:00|\n",
      "|       C|      CI|2023-09-02T12:00:00|\n",
      "|       C|      CI|2023-09-02T13:00:00|\n",
      "|       C|      CI|2023-09-02T14:00:00|\n",
      "|       C|      CI|2023-09-02T15:00:00|\n",
      "|       C|      CI|2023-09-02T16:00:00|\n",
      "|       C|      CI|2023-09-02T17:00:00|\n",
      "|       C|      CI|2023-09-02T18:00:00|\n",
      "|       C|      CI|2023-09-02T19:00:00|\n",
      "|       C|      CI|2023-09-02T20:00:00|\n",
      "|       C|      CI|2023-09-02T21:00:00|\n",
      "|       C|      CI|2023-09-02T22:00:00|\n",
      "|       C|      CI|2023-09-02T23:00:00|\n",
      "+--------+--------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "df.select('DK19Code','DK36Code','HourDK').filter((col('DK19Code')=='C') & (col('DK36Code')=='CI') ).distinct().orderBy('HourDK').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7695faa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+\n",
      "|DK19Code|DK36Code|count|\n",
      "+--------+--------+-----+\n",
      "|       A|       A|  360|\n",
      "|       B|       B|  360|\n",
      "|       C|      CA|  360|\n",
      "|       C|      CC|  360|\n",
      "|       C|CE_CF_CD|  360|\n",
      "|       C|      CG|  360|\n",
      "|       C|      CH|  360|\n",
      "|       C|      CI|  360|\n",
      "|       C|      CJ|  360|\n",
      "|       C|      CK|  360|\n",
      "|       C|      CL|  360|\n",
      "|       C|   CM_CB|  360|\n",
      "|       D|       D|  360|\n",
      "|       E|       E|  360|\n",
      "|       F|       F|  360|\n",
      "|       G|       G|  360|\n",
      "|       H|       H|  360|\n",
      "|       I|       I|  360|\n",
      "|       J|      JA|  360|\n",
      "|       J|   JB_JC|  360|\n",
      "|       K|       K|  360|\n",
      "|       L|       L|  360|\n",
      "|       M|      MA|  360|\n",
      "|       M|      MB|  360|\n",
      "|       M|      MC|  360|\n",
      "|       N|       N|  360|\n",
      "|       O|       O|  360|\n",
      "|       P|       P|  360|\n",
      "|      PR|      PR|  360|\n",
      "|       Q|      QA|  360|\n",
      "+--------+--------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Group by DK19Code, DK36Code to count number of rows\n",
    "df.groupBy('DK19Code','DK36Code').count().orderBy('DK19Code','DK36Code').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a7d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdk.common_modules.delta.delta_state import DeltaState\n",
    "\n",
    "storage_account_name = \"adlsthuehomelakehousedev\"\n",
    "container_name = \"landing\"\n",
    "dataset_name = \"ConsumptionDK3619codehour\"\n",
    "\n",
    "\n",
    "# Create DeltaState object\n",
    "delta_state = DeltaState(spark, storage_account_name, container_name, dataset_name)\n",
    "\n",
    "# Set delta state\n",
    "# delta_state.set_delta_state(\"2023-09-03T00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15f421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 16:43:04 WARN DFSPropertiesConfiguration: Cannot find HUDI_CONF_DIR, please set it as the dir of hudi-defaults.conf\n",
      "23/09/24 16:43:04 WARN DFSPropertiesConfiguration: Properties file file:/etc/hudi/conf/hudi-defaults.conf not found. Ignoring to load props file\n",
      "23/09/24 16:43:17 WARN HoodieBackedTableMetadata: Metadata table was not found at path abfss://utility@adlsthuehomelakehousedev.dfs.core.windows.net/delta/delta_table/.hoodie/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2023-01-01T00:00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_state.get_delta_state(default_value=\"2023-01-01T00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746afa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       commitTime|\n",
      "+-----------------+\n",
      "|20230924164310010|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "delta_path = f\"abfss://utility@{storage_account_name}.dfs.core.windows.net/delta/delta_table\"\n",
    "\n",
    "df = spark.read.format(\"hudi\").load(delta_path).createOrReplaceTempView(\"hudi_delta_snapshot\")\n",
    "\n",
    "spark.sql(\"select distinct(_hoodie_commit_time) as commitTime from  hudi_delta_snapshot order by commitTime\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf0bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/24 16:49:15 WARN HoodieFileIndex: No partition columns available from hoodie.properties. Partition pruning will not work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+-------------------+-------------------+\n",
      "|               key|type|  filesystemMetadata|BloomFilterMetadata|ColumnStatsMetadata|\n",
      "+------------------+----+--------------------+-------------------+-------------------+\n",
      "|__all_partitions__|   1|   {. -> {0, false}}|               null|               null|\n",
      "|                 .|   2|{927fee05-73c9-47...|               null|               null|\n",
      "+------------------+----+--------------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read hudi metadata from delta table\n",
    "df = spark.read.format(\"hudi\").load(delta_path+'/.hoodie/metadata')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089c27c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
