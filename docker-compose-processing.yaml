


version: "3.6"
services:
  ad-hoc:
    extends:
      file: docker-compose-spark.yaml
      service: ad-hoc
  spark-master:
    extends:
      file: docker-compose-spark.yaml
      service: spark-master
  spark-worker-1:
    extends:
      file: docker-compose-spark.yaml
      service: spark-worker-1

  postgresql:
    # image: docker.io/bitnami/postgresql:15
    build:
      context: ./
      dockerfile: docker/postgresql/Dockerfile
    volumes:
      - ./data/postgresql_data:/bitnami/postgresql/data
    environment:
      - POSTGRESQL_DATABASE=bitnami_airflow
      - POSTGRESQL_USERNAME=bn_airflow
      - POSTGRESQL_PASSWORD=bitnami1
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '5432:5432'
    networks:
      - my_persistent_network 
  redis:
    # image: docker.io/bitnami/redis:7.0
    build:
      context: ./
      dockerfile: docker/redis/Dockerfile
    volumes:
      - './data/redis_data:/bitnami'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - my_persistent_network 
  airflow-scheduler:
    build:
      context: ./
      dockerfile: docker/airflow-scheduler/Dockerfile
    # image: airflow-scheduler
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflow
      - AIRFLOW_LOAD_EXAMPLES=no
      # - PYTHONPATH=/opt/bitnami/airflow/dags:/opt/bitnami/airflow/plugins:/opt/bitnami/python/scripts
    volumes:
      - ./src/airflow_dags:/opt/bitnami/airflow/dags
      - ./src/jupyter/apps:/opt/bitnami/spark/apps
      # - ./src/jupyter/scripts:/opt/bitnami/python/scripts
      # - ./dependencies/requirements.txt:/bitnami/python/requirements.txt
    networks:
      - my_persistent_network 
  airflow-worker:
    build:
      context: ./
      dockerfile: docker/airflow-worker/Dockerfile
    # image: airflow-worker
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflow
      - AIRFLOW_LOAD_EXAMPLES=no
      - PYTHONPATH=/opt/bitnami/airflow/dags:/opt/bitnami/airflow/plugins:/opt/bitnami/python/scripts
      - ADLS_adlsthuehomelakehousedev_access_key=$data_lake_access_key
      - el_overblik_api_token=$el_overblik_api_token
    volumes:
      - ./src/airflow_dags:/opt/bitnami/airflow/dags
      - ./src/ad-hoc/apps:/opt/bitnami/spark/apps
      - ./src/ad-hoc/scripts:/opt/bitnami/python/scripts
      # - ./dependencies/requirements.txt:/bitnami/python/requirements.txt
    networks:
      - my_persistent_network 
  airflow:
    build:
      context: ./
      dockerfile: docker/airflow/Dockerfile
    # image: airflow
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_PASSWORD=bitnami
      - AIRFLOW_USERNAME=user
      - AIRFLOW_EMAIL=user@example.com
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflow
      - AIRFLOW_LOAD_EXAMPLES=no
      # - PYTHONPATH=/opt/bitnami/airflow/dags:/opt/bitnami/airflow/plugins:/opt/bitnami/python/scripts
      # - AIRFLOW_HOME=/opt/bitnami/airflow
    volumes:
      - ./src/airflow_dags:/opt/bitnami/airflow/dags
      - ./settings/airflow:/.vscode-server
      # - ./src/jupyter/apps:/opt/bitnami/spark/apps
      # - ./src/jupyter/scripts:/opt/bitnami/python/scripts
      # - ./dependencies/requirements.txt:/bitnami/python/requirements.txt
    ports:
      - '9080:8080' 
    networks:
      - my_persistent_network 

networks:
  my_persistent_network:
    driver: bridge